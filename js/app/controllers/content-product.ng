<div ng-if="!contentCtrl.productInfo">
  <h2>Error</h2>
  <p class="text">No information for product {{ contentCtrl.currentProduct }}.</p>
</div>

<!-- Product-specific copy. Usually cribbed from the marketing page. -->
<div
    class="psr-textBlock"
    ng-if="contentCtrl.productInfo"
    ng-switch="contentCtrl.currentProduct">
  
  <!-- Compute Engine -->
  <div ng-switch-when="google-compute-engine">
    <p>
      Google Compute Engine lets you create and run virtual machines on Google
      infrastructure. Compute Engine offers scale, performance, and value that
      allows you to easily launch large compute clusters on Google's
      infrastructure. There are no upfront investments and you can run
      thousands of virtual CPUs on a system that has been designed to be fast,
      and to offer strong consistency of performance.
    </p>

    <h2>Instances</h2>
    <p>
      Google Compute Engine VMs are referred to as <em>instances</em>. To create
      an instance, you must first create an <em>instance configuration</em>.
      This requires at the minimum a name, a machine type, and a boot disk
      image or preexisting boot disk.
    </p>
    <p>
      Once you have your configuration object, you can send them to the
      <cmdlet-ref name="Add-GceInstance"></cmdlet-ref> cmdlet to build them of a
      particular project and zone. If your active gcloud configuration has a
      project and zone, then those parameters are optional.
    </p>
    <pre>
# Define the project name you want to create the instance in. If not set, the
# command will use the current default project specified by gcloud config.
$project = "&lt;your-project-name&gt;"

# Define the configuration for an instance called "webserver-1"
$config = New-GceInstanceConfig "webserver-1" -MachineType "n1-standard-4" `
          -DiskImage (Get-GceImage -Family "windows-2012-r2")

# Attempt to create the instance based on the configuration
$config | Add-GceInstance -Project $project -Zone "us-central1-b"</pre>
    <h2>Management</h2>
    <p>
      In addition to basic cmdlets to start, stop, or restart an instance,
      You can set tags, disks, access configs or metadata after creating
      your VM with the <cmdlet-ref name="Set-GceInstance"></cmdlet-ref> cmdlet.
    </p>
    <pre>
$instance = "&lt;your-instance-name&gt;"

# Fetch information about the instance
Get-GceInstance $instance

# Stop, start, restart the instance
Stop-GceInstance $instance
Start-GceInstance $instance
Restart-GceInstance $instance
  
# Add a new network access configuration to the instance
[Google.Apis.Compute.v1.Data.AccessConfig] $newConfig = @{}
$newConfig.Kind = "ONE_TO_ONE_NAT"
$newConfig.Name = "New NAT"

Set-GceInstance "instance-name" `
    -NetworkInterface "nic0" 
    -RemoveAccessConfig "External NAT"
    -NewAccessConfig $newConfig

# Edit the metadata and tags on the instance
Set-GceInstance "instance-name" -AddMetadata @{"newKey" = "newValue"}
Set-GceInstance "instance-name" -RemoveMetadata "newKey"
Set-GceInstance "instance-name" -RemoveTag "beta" -AddTag "alpha"</pre>  
  </div>


  <!-- Cloud Storage -->
  <div ng-switch-when="google-cloud-storage">
    <p>
      Google Cloud Storage allows world-wide storage and retrieval of any
      amount of data at any time. You can use Google Cloud Storage for a range
      of scenarios including serving website content, storing data for archival
      and disaster recovery, or distributing large data objects to users via
      direct download.
    </p>
    <h2>Buckets</h2>
    <p>
      Google Cloud Storage data is grouped into "buckets".
    </p>
    <pre>
# List all buckets associated with a project
$project = "&lt;your-project-name&gt;"
Get-GcsBucket -Project $project

# Create a new bucket in the project
New-GcsBucket -Project $project -Name "&lt;your-bucket-name&gt;"</pre>
    <h2>Objects</h2>
    <p>
      Each bucket contains "objects", which contain arbitrary data.
    </p>
    <pre>
$bucket = "&lt;your-bucket-name&gt;"

# List all objects in a GCS bucket.
Find-GcsObject -Bucket $bucket

# Upload a file to the bucket in a "test" folder,
# renames it in passing from "test-file.png" to "test.png"
# NOTE: This will fail unless you have permissions to write in the bucket.
Write-GcsObject -Bucket $bucket -File "test-file.png" -ObjectName "test/test.png"

# Download a GCS object to disk.
Read-GcsObject $bucket "object-name" -OutFile "output-file.png"</pre>
    <h2>Cloud Storage PowerShell Provider</h2>
    <p>
      Cloud Tools for PowerShell includes a PowerShell provider for Google Cloud Storage.
      This provider allows you to use commands like <code>cd</code>, <code>dir</code>, <code>copy</code> and <code>del</code> to navigate
      and manipulate your data in Cloud Storage as if the data were on a local file system.

      To directly use the provider, you can start Cloud Tools for PowerShell using the shortcut
      from the start menu. This will launch a PowerShell console with the provider loaded:
    </p>
    <pre>
# Navigate to Google Cloud Storage
cd gs:\

# Show the available buckets
dir

# Create a new bucket
mkdir my-new-bucket</pre>
    <p>
      You can also make the provider available in any PowerShell session by importing
      the Cloud Tools for PowerShell module via <code>Import-Module GoogleCloud</code>.
    </p>
  </div>
  
    <!-- Google Cloud BigQuery -->
  <div ng-switch-when="google-cloud-bigquery">
    <p>
      Google BigQuery is a versatile tool that solves the problem of storing and querying massive 
      datasets without having to worry about data formats, underlying resources, and other things 
      that distract you from your analysis.
    </p>
    
    <h2>Dataset</h2>
    <p>
      To use BigQuery in a Cloud project, first create a <em>Dataset</em> using the 
      <cmdlet-ref name="New-BqDataset"></cmdlet-ref> cmdlet. This will take in basic information and 
      create the resource serverside. Locally, a reference Dataset object is returned. To get a reference
      object for an existing dataset, use <cmdlet-ref name="Get-BqDataset"></cmdlet-ref>.
    </p>
    <pre>
# Makes a new dataset with DatasetId "my_dataset".
$dataset = New-BqDataset "my_dataset" -Name "Test Dataset" -Description "Some test data for BigQuery"

# The following two lines do the same thing.
$dataset = Get-BqDataset "my_dataset"
$dataset = $dataset | Get-BqDataset
    </pre>
    <p>
      This object <em>$dataset</em> can be modified and passed into further cmdlets such as 
      <cmdlet-ref name="Set-BqDataset"></cmdlet-ref> to manipulate cloud resources. This cmdlet also
      handles adding and removing labels with <code>-SetLabel</code> and <code>-ClearLabel</code>.
    </p>
    <pre>
# Updates the Name field of $dataset.
$dataset.Name = "A Different Name"
$dataset = Set-BqDataset "my_dataset"

# Adds the labels 'test' and 'other' to $dataset.
$dataset = Set-BqDataset "my_dataset" -SetLabel @{"test"="one";"other"="two"}
    </pre>
    <p>
      Datasets can be deleted by the <cmdlet-ref name="Remove-BqDataset"></cmdlet-ref> cmdlet. This 
      cmdlet supports ShouldProcess (the <code>-WhatIf</code> parameter) and will prompt for user 
      confirmation before deleting a non-empty Dataset. This safeguard can be bypassed with the 
      <code>-Force</code> parameter when scripting.  
    </p>
    <pre>
# Deletes $dataset.
$dataset | Remove-BqDataset -Force
    </pre>
    
    <h2>Table</h2>
    <p>
      Each Dataset has a number of <em>Tables</em> to hold data. Tables are created with the 
      <cmdlet-ref name="New-BqTable"></cmdlet-ref> cmdlet by passing in a TableId and a Dataset 
      where the table will reside. The Dataset can be passed with a Dataset object or with the
      <code>-DatasetId</code> parameter. <cmdlet-ref name="Get-BqTable"></cmdlet-ref> and 
      <cmdlet-ref name="Set-BqTable"></cmdlet-ref> work the same way as the Get- and Set- cmdlets above.
    </p>
    <pre>
# Creates a new table in the dataset from above.
$table = $dataset | New-BqTable "my_table" -Description "Log data"

# Gets a reference object for "my_dataset:my_table".
$table = Get-BqTable "my_table" -DatasetId "my_dataset"

# Modifies the Name attribute of my_table.
$table.Name = "Logs"
$table = $table | Set-BqTable
    </pre>
    <p>
      Tables can be deleted by the <cmdlet-ref name="Remove-BqTable"></cmdlet-ref> cmdlet. This 
      cmdlet supports ShouldProcess (the <code>-WhatIf</code> parameter) and will prompt for user 
      confirmation before deleting a Table that contains data. This safeguard can be bypassed with 
      the <code>-Force</code> parameter.  
    </p>
    <pre>
# Deletes $table.
$table | Remove-BqTable -Force
    </pre>
    
    <h2>Schema</h2>
    <p>
      Tables need <em>Schemas</em> to describe the format of the data they contain. Schemas are created with
      the <cmdlet-ref name="New-BqSchema"></cmdlet-ref> and <cmdlet-ref name="Set-BqSchema"></cmdlet-ref>
      cmdlets. New-BqSchema can take the formats for rows as parameters directly or as a JSON array of 
      row descriptions. The results of New-BqSchema are always passed into Set-BqSchema which can either output
      a Schema object or assign the Schema to an existing Table.  
    </p>
    <pre>
# Assigns a Schema to $table
$table = Get-BqTable "my_table" -DatasetId "my_dataset"
New-BqSchema "Author" "STRING" | New-BqSchema "Copyright" "STRING" | 
    New-BqSchema "Title" "STRING" | Set-BqSchema $table

# Creates a schema object to be used in multiple tables.
$schema = New-BqSchema "Author" "STRING" | New-BqSchema "Copyright" "STRING" | 
          New-BqSchema "Title" "STRING" | Set-BqSchema $table
    </pre>
    <p>
      Schema objects can be passed as parameters in Table creation if they are created ahead of time.
    </p>
    <pre>
# Creates a new table with the Schema object from above.
$table = $dataset | New-BqTable "my_table" -Schema $schema
    </pre>
    
    <h2>TableRow</h2>
    <p>
      Data is added and removed from Tables in Rows. These Rows are accessible using the 
      <cmdlet-ref name="Add-BqTableRow"></cmdlet-ref> and <cmdlet-ref name="Get-BqTableRow"></cmdlet-ref>
      cmdlets. Add-BqTableRow takes CSV, JSON, and AVRO files to import into BigQuery.
    </p>
    <pre>
# Ingests a CSV file and appends its rows onto the table 'my_dataset:my_table'.
$table = New-BqTable "my_table" -DatasetId "my_dataset"
$table | Add-BqTableRow CSV $filename -SkipLeadingRows 1 -WriteMode WriteAppend

# Returns a list of the rows in 'book_data:classics'.
$list = Get-BqTable "classics" -DatasetID "book_data" | Get-BqTableRow
    </pre>
    
    <h2>Jobs</h2>
    <p>
      There are four types of jobs: Query, Load, Extract, and Copy. Query jobs run SQL style queries and 
      output results to tables. Load jobs import Google Cloud Storage files into BigQuery. Extract jobs 
      export BigQuery tables to GCS. Copy jobs copy an existing table to another new or existing table.
      <cmdlet-ref name="Start-BqJob"></cmdlet-ref> starts any of these kinds of jobs as an asynchronous 
      operation. Use the <code>-PollUntilComplete</code> flag to have the cmdlet block until the job is done.
      <cmdlet-ref name="Receive-BqJob"></cmdlet-ref> will return the results of a query job once it is 
      finished. <cmdlet-ref name="Get-BqJob"></cmdlet-ref> will return a reference object detailing the
      current state and statistics on the job.  <cmdlet-ref name="Stop-BqJob"></cmdlet-ref> will send a 
      request to the server to stop a certain job, and then returns immediately.
    </p>
    <pre>
# Query Job: starts a query and outputs results into $table.
Start-BqJob -Query "SELECT * FROM ``my_dataset:my_table``" -Destination $table
    </pre>
    <pre>
# Load Job: adds TableRows to $table from the GCS file specified.
$job = $dest_table | Start-BqJob -Load CSV "gs://my_dataset/data.csv"
    </pre>
    <pre>
# Extract Job: exports $src_table to a GCS file.
$job = $src_table | Start-BqJob -Extract CSV "gs://my_dataset/data.csv"
    </pre>
    <pre>
# Copy Job: Starts a copy job, cancels it, and polls until the job is complely done.
$job = $table | Start-BqJob -Copy $target
$result = $job | Stop-BqJob
while ($result.Status.State -ne "DONE") {
    $result = $result | Get-BqJob
}
    </pre>
  </div>

  <!-- Google Cloud DNS -->
  <div ng-switch-when="google-cloud-dns">
    <p>
      Google Cloud DNS is a high-performance, resilient, global Domain Name 
      System (DNS) service that publishes your domain names to the global DNS 
      in a cost-effective way. You can use Google Cloud DNS to publish your 
      zones and records in the DNS without the burden of managing your own DNS 
      servers and software.
    </p>
    <h2>Managed Zones</h2>
    <p>
      In Cloud DNS, a managed zone models a DNS zone and holds DNS records for  
      the same DNS name suffix (e.g., <code class="code">dnsexample.com.</code>). You can add a zone 
      to your Google Cloud Console project using the <cmdlet-ref name="Add-GcdManagedZone"></cmdlet-ref>
      cmdlet. Each zone in your project must have a unique name and a unique 
      DNS name to specify its associated DNS name suffix.  
    </p>
    <pre>
$project = "&lt;your-project-name&gt;"

# Create a managed zone for the DNS suffix dnsexample.com.
$zone = "&lt;your-zone-name&gt;"
$dnsSuffix = "&lt;dnsexample.com.&gt;"
Add-GcdManagedZone -Project $project -Name $zone -DnsName $dnsSuffix

# List all the managed zones in your project.
Get-GcdManagedZone -Project $project</pre>
    <h2>Resource Record Sets</h2>
    <p>
      <a href="https://cloud.google.com/dns/records/json-record">ResourceRecordSets</a> in Cloud  
      DNS are DNS records that you can create using the <cmdlet-ref name="New-GcdResourceRecordSet"></cmdlet-ref>
      cmdlet and retrieve from a managed zone using the <cmdlet-ref name="Get-GcdResourceRecordSet"></cmdlet-ref>
      cmdlet.
    </p>
    <p>
      However, to actually add or remove records from a managed zone, you must send
      a change request to the zone using the <code>Add-GcdChange</code> cmdlet. 
    </p>
    <pre>
# Create a new A-type resource record for "dnsexample.com." and point it to
# an IPv4 address.
$ipv4 = "107.1.23.134"
$ARecord = New-GcdResourceRecordSet -Name $dnsSuffix -Rrdata $ipv4 -Type "A"

# Add the record to your zone. 
Add-GcdChange -Project $project -Zone $zone -Add $ARecord

# Retrieve the newly added A-type record.  
$ARecord = Get-GcdResourceRecordSet -Project $project -Zone $zone -Filter "A"

# Remove the retrieved record from your zone.
Add-GcdChange -Project $project -Zone $zone -Remove $ARecord</pre>
  </div>


  <!-- Google Cloud SQL -->
  <div ng-switch-when="google-cloud-sql">
    <p>
      Google Cloud SQL lets you set-up, maintain, manage, and administer
      your relational MySQL databases on Google's Cloud Platform.
    </p>
    <h2>Instances</h2>
    <p>
      Google Cloud SQL instances hold all of your MySQL databases
      and their relevant data. To create an instance, you must first
      create an <em>Cloud SQL instance configuration</em>. This requires, at the
      minimum, a name for your instance, and a <em>setting configuration</em>,
      which doesn't require anything.
    </p>
    <p>
      After the configuration object has been made, the <cmdlet-ref name="Add-GcSqlInstance"></cmdlet-ref>
      cmdlet can be called to create that instance in a particular project.
      If your active gcloud configuration has a project, the parameter is optional.
    </p>
    <pre>
$setting = New-GcSqlSettingConfig 
$instance = New-GcSqlInstanceConfig `
    "my-instance-name" -SettingConfig $setting

$instance | Add-GcSqlInstance -Project $myProjectName</pre>
    <h2>Importing Data</h2>
    <p>
      MySQL dump filles and CSV files on either your local machine
      or on a Google Cloud Storage Bucket can be imported to your instance's
      databases with the <cmdlet-ref name="Import-GcSqlInstance"></cmdlet-ref>.
    </p>
    <pre>
Import-GcSqlInstance "my-instance-name" "C:\Users\User\file.csv" `
    "destination-database" "destination-table"</pre>  
  </div>

  <!-- Google Cloud PubSub -->
  <div ng-switch-when="google-cloud-pubsub">
    <p>
      Google Cloud Pub/Sub is a fully-managed real-time messaging service that
      allows you to send and receive messages between independent applications.
    </p>
    <h2>Publisher</h2>
    <p>
      The publisher application creates and sends messages to a <em>topic</em>.
      The <cmdlet-ref name="New-GcpsTopic"></cmdlet-ref> cmdlet can be called to create an instance
      in a particular topic. If your active gcloud configuration has a project, you don't have to
      use the <code>-Project</code> parameter.
    </p>
    <pre>
# Creates topic "my-topic" in the default project.
New-GcpsTopic -Topic "my-topic"</pre>
    <p>
      After the topic has been created, you can now publish messages to the topic using the
      <cmdlet-ref name="Publish-GcpsMessage"></cmdlet-ref> cmdlet.
    </p>
    <pre>
# Publishes the message with data "This is a test" to topic "my-topic".
Publish-GcpsMessage -Data "This is a test" -Topic "my-topic"</pre>
    <p>
      To publish multiple messages to the same topic with a single request, you can use the
      <cmdlet-ref name="New-GcpsMessage"></cmdlet-ref> cmdlet to create an array of messages
      and pass that to the <cmdlet-ref name="Publish-GcpsMessage"></cmdlet-ref> cmdlet.
    </p>
    <pre>
# Creates two messages.
$messageOne = New-GcpsMessage -Data "This is a test"
$messageTwo = New-GcpsMessage -Data "Data" -Attributes @{"key" = "value"}
      
# Publish the messages to topic "my-topic".
Publish-GcpsMessage -Message @($messageOne, $messageTwo) -Topic "my-topic"</pre>
    <h2>Subscriber</h2>
    <p>
      The subscriber application creates a <em>subscription</em> to a topic to receive messages from it.
      The <cmdlet-ref name="New-GcpsSubscription"></cmdlet-ref> cmdlet can be called to create an instance
      in a particular topic. If your active gcloud configuration has a project, you don't have to
      use the <code>-Project</code> parameter.
    </p>
    <p>
      By default, the subscription created is a pull subscription, which means the subscriber will
      pull the messages from the topic. You can create a push subscription (Pub/Sub will push messages
      to the subscriber's chosen endpoint) with <code>-PushEndpoint.</code>
    </p>
    <pre>
# Creates pull subscription "pull-subscription" to topic "my-topic" in the default project.
New-GcpsSubscription -Topic "my-topic" -Subscription "pull-subscription"

# Creates push subscription "push-subscription" to topic "my-topic".
New-GcpsSubscription -Topic "my-topic" `
                     -Subscription "push-subscription" `
                     -PushEndpoint "http://www.example.com"</pre>
    <p>
      To pull messages from a subscription, the <cmdlet-ref name="Get-GcpsMessage"></cmdlet-ref> cmdlet can
      be used. By default, the cmdlet will block until at least one message is retrieved. To prevent blocking,
      the switch <code>-ReturnImmediately</code> can be used. The cmdlet can also automatically send
      an acknowledgement for every retrieved message if the switch <code>-AutoAck</code> is used. If not,
      you will have to use the <cmdlet-ref name="Send-GcpsAck"></cmdlet-ref> cmdlet to send the acknowledgement.
      Unacknowledged messages will become available again for pulling after the acknowledgement deadline of the message expires.
    </p>
    <pre>
# Pulls messages from subscription "my-subscription" and sends out acknowledgement automatically.
Get-GcpsMessage -Subscription "my-subscription" -AutoAck

# Pulls messages from subscription "my-subscription" and sends out acknowledgement with Send-GcpsAck.
$messages = Get-GcpsMessage -Subscription "my-subscription"
Send-GcpsAck -InputObject $messages</pre>
  </div>

  <!-- Google Cloud Logging -->
  <div ng-switch-when="google-cloud-logging">
    <p>
      Stackdriver Logging allows you to store, search, analyze, monitor and alert on log data
      and events from Google Cloud Platform and Amazon Web Services.
    </p>
    <h2>Logs and Log Entries</h2>
    <p>
      A log is a named collection of log entries within the project. A log entry records status or an event.
      The entry might be created by GCP services, AWS services, third party applications, or your own applications.
      The "message" the log entry carries is called the payload, and it can be a simple string or structured data.
      Each log entry indicates where it came from by including the name of a monitored resource.
    </p>
    <p>
      The cmdlet <cmdlet-ref name="New-GcLogEntry"></cmdlet-ref> can be used to create a log entry.
      You will have to specify the log that the entry belongs to (if the log does not exist, it will
      be created). To associate the log with a monitored resource, you can use the -MonitoredResource parameter.
      By default, the log entry is associated with the "global" resource. To create a monitored resource,
      use the <cmdlet-ref name="New-GcLogMonitoredResource"></cmdlet-ref> cmdlet.
  </p>
    <pre>
# Creates a log entry in the log "my-log".
New-GcLogEntry -LogName "my-log" -TextPayload "This is a log."

# Creates a log entry associated with a Cloud SQL monitored resource.
$resource = New-GcLogMonitoredResource -ResourceType "cloudsql_database" `
                                       -Labels @{"project_id" = "my-project";
                                                 "database_id" = "id"}
New-GcLogEntry -LogName "my-log" `
               -TextPayload "This is a log." `
               -MonitoredResource $resource</pre>
    <p>
      You can retrieve log entries with the cmdlet <cmdlet-ref name="Get-GcLogEntry"></cmdlet-ref>.
    </p>
    <pre>
# Gets all entries from log "my-log"
Get-GcLogEntry -LogName "my-log"

# Gets all entries associated with Google Cloud Engine instances.
Get-GcLogEntry -ResourceName "gce_instance"</pre>
    <h2>Log Sinks</h2>
    <p>
      To export log entries, you can create log sinks with the cmdlet <cmdlet-ref name="New-GcLogSink"></cmdlet-ref>.
      Stackdriver Logging will match incoming log entries against your sinks and all log entries matching each sink
      are then copied to the associated destination. Log entries that exist before the sink is created will not be exported.
    </p>
    <p>
      Destinations for exported logs can be Google Cloud Storage Buckets, Google BigQuery Datasets
      or Google Cloud Pub/Sub Topics.
    </p>
    <pre>
# Creates a log sink for log entries in the default project.
# The entries will be sent to the GCS bucket "my-bucket".
New-GcLogSink -Sink "my-sink" -GcsBucketDestination "my-bucket"

# Creates a log sink for log entries in log "my-log".
# The entries will be sent to the BigQuery data set "my_dataset".
New-GcLogSink -Sink "my-sink" `
              -LogName "my-log" `
              -BigQueryDataSetDestination "my_dataset"

# Creates a log sink for log entries that match the filter.
# The entries will be sent to the Pub/Sub topic "my-topic".
New-GcLogSink -Sink "my-sink" `
              -Filter "textPayload = `"Testing`"" `
              -PubSubTopicDestination "my-topic"</pre>
    <h2>Log Metrics</h2>
    <p>
      You can create log metrics that count the number of log entries that match a certain criteria
      with the cmdlet <cmdlet-ref name="New-GcLogMetric"></cmdlet-ref>. These metrics can be used
      to create charts and alerting policies in Stackdriver Monitoring.
  </p>
    <pre>
# Creates a metric for entries in log "my-log".
New-GcLogMetric -Metric "my-metric" -LogName "my-log"

# Creates a metric for entries associated with Google Cloud Engine instances.
New-GcLogMetric -Metric "my-metric" -ResourceType "gce_instance"

# Creates a metric for entries that match the filter.
New-GcLogMetric -Metric "my-metric" -Filter "textPayload = `"Testing`""</pre>
  </div>

  <!-- Google Cloud IAM -->
  <div ng-switch-when="google-cloud-iam">
    <p>
      Google Cloud Identity & Access Management (IAM) allows you manage fine-grainted access control
      and visibility for centrally managing cloud resources.
    </p>
    <h2>IAM policy bindings</h2>
    <p>
      An IAM policy binding describes the access that an entity has to a cloud resources.
      The cmdlet <cmdlet-ref name="Add-GcIamPolicyBinding"></cmdlet-ref> can be used to add an
      IAM policy binding. You will have to specify the access level with -Role parameter.
      The entity that the role applies to is specified with either -User, -Group, -ServiceAccount
      or -Domain (which corresponds to a Google account email address, a Google group email address,
      a service account email address and a domain respectively). If -Project parameter is not used,
      the cmdlet will add the binding to resources in the default project.
    </p>
    <pre>
# Gives user test-user@google.com owner role in the project "my-project".
Add-GcIamPolicyBinding -Role roles/owner -User test-user@google.com -Project "my-project"

# Gives group test-group@google.com browser role in the default project.
Add-GcIamPolicyBinding -Role roles/browser -Group test-group@google.com</pre>
    <p>
      You can view existing bindings with the cmdlet <cmdlet-ref name="Get-GcIamPolicyBinding"></cmdlet-ref>.
      The cmdlet will use the default project if -Project parameter is not used.
    </p>
    <pre>
# Gets all IAM policy bindings in the project "my-project".
Get-GcIamPolicyBinding -Project "my-project"</pre>
    <p>
      You can remove existing bindings with the cmdlet <cmdlet-ref name="Remove-GcIamPolicyBinding"></cmdlet-ref>.
      The cmdlet will not raise an error if the binding does not exist.
    </p>
    <pre>
# Removes the container admin role of the service account
# service@project.iam.gserviceaccount.com in the default project.
Remove-GcIamPolicyBinding -Role roles/container.admin -ServiceAccount service@project.iam.gserviceaccount.com

# Removes the editor role of all users of the domain
# example.com in the default project.
Remove-GcIamPolicyBinding -Role roles/editor -Domain example.com</pre>
  </div>

  <!-- Google Cloud Project -->
  <div ng-switch-when="google-cloud-project">
    <p>
      Google Cloud Project cmdlets let you manage your project.
    </p>
    <h2>Google Cloud Projects</h2>
    <p>
      The cmdlet <cmdlet-ref name="Get-GcpProject"></cmdlet-ref> lists all Google Cloud projects
      that you have access to.
    </p>
    <pre>
# Lists all available Google Cloud projects.
Get-GcpProject</pre>
  </div>

  <!-- Default. Should not get here if cmdlet data is well-formed. -->
  <div ng-switch-default>
  </div>

  <h2>All Resources</h2>
  <table class="psr-linkTable">
    <tr>
      <th>Resource</th>
    </tr>
    <tr ng-repeat="resource in contentCtrl.productInfo.resources | orderBy:'name'">
      <td>
        <a href="/google-cloud-powershell/#/{{ contentCtrl.productInfo.name }}/{{ resource.name }}">
          <div>
            {{ resource.name }}
          </div>
        </a>
      </td>
    </tr>
  </table>
</div>
